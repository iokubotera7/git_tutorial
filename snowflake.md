# データロード
Snowflakeでは、以下からのデータをSnowflakeにアップロードすることができる。
* ローカルデータ
* Amazon S3
* Google Cloud Storage
* Microsoft Azure

## データロードの手順
1. PUTコマンドを使用して、データファイルをデータロードの中間領域にアップロード（ステージング）する。
2. COPY INTO <テーブル>コマンドを使用して、ステージングされたファイルの内容をSnowflakeデータベーステーブルにアップロードする。

すなわち、S3⇒ステージング⇒テーブルの順番になる、  
このとき、ステージングからテーブルまでのデータのアップロードにCOPY INTO <テーブル>が用いられる。

まずは、PUTコマンドでファイルをステージングへ、ステージングにあるデータをCOPY INTO <テーブル>でテーブルへ。

1. createコマンドで内部ステージを作成
2. putコマンドでステージへファイルをアップロード
3. copy into コマンドでステージからsnowflakeのテーブルへアップロード


データをロードするには、ウェアハウスが必要。  

どのサブネットがどのインタネーットゲートウェイとつながっているのを記載。

EgressインターネットGW：IPv6専用のインターネットGW  


キャリアゲートウェイ：5G専用のゲートウェイ

Elastic IPアドレス：固定IPアドレス

マネージドプレフィックスリスト：IPアドレス範囲をリストとして設定する
エンドポイントはVPCの外のAWSのサービスとやり取りする。
エンドポイントサービスの作成：VPCのサービスを他のAWSアカウントを利用させるための設定

NATゲートウェイ：プライベートサブネットからのインターネット外へのトラフィック転送の機能。

ピアリング接続：VPC同士の接続に用いる。

ネットワークACL：VPCへのトラフィックの許可・拒否の設定
セキュリティグループ：インスタンス用のセキュリティ設定
Route53 Resolver DNS Firewall： DNSクエリのセキュリティ
AWS Network Firewall：VPCのファイアウォール。Network Firewall用のサブネットを作成し、Firewallが許可したトラフィックのみサブネットに転送する。  
カスタマーゲートウェイ：VPNや専用線接続などを用いて、オンプレミス環境との接続に用いる。
仮想プライベートゲートウェイ：VPNで接続するのに用いる。
VPN接続：VPCとVPNで接続するのに用いる。
Transit Gateway：複数のVPC間の接続に用いる。
Network Manager：VPCへのアクセス状況の確認やネットワークの全体的な管理、セキュリティの確認等が可能。  


AZ：データセンタの場所。冗長化を考えると複数あった方がいい。ap-XXX、ap-XXXみたいなの

ルートテーブルはルータの中に配置される。
そのため、パブリックサブネットを作成するためには、サブネット内のルータとインターネットGW内のルータそれぞれのルートテーブに  
ルーティングする必要がある。  

すべてのIPアドレス（ループバックアドレスを除く）0.0.0.0はインターネットGWに転送する。

IPマスカレード：複数のプライベートIPアドレスをグローバルIPアドレスに変換する。  

プライベートサブネットへのダイレクトなインターネットからのインバウンド通信は不可。
そんため、インターネットからのインバウンド通信には、パブリックサブネットに踏み台サーバを設置し、  
台サーバを経由してプライベートサブネットへアクセスする。  
プライベートサブネットからインターネットへのアウトバウンド通信は、NATゲートウェイを介して通信する。  

AMIの選択
  OSイメージの選択(Amazon Linuxなど)
インスタンスタイプ
  CPUのクロック数とコア数
  メモリ容量
ストレージタイプ
  ネットワークディスク（EBS）
  
EC2は任意のAZにインスタンスを立ち上げる  

インスタンスタイプの種類
t2.nano
tというのはファミリー。汎用型、コンピューティング最適化、メモリ最適化、ストレージ最適化、高速コンピューティングなどがある。
2は世代、１とか３とかもある。
nanoはインスタンスの容量

インスタンスストア：EC2に内蔵されていて、EC2の一時的なデータが保持され、EC2の停止・終了されるとデータ削除される。無料  
Elastic Block Store(EBS)：EC2とは独立して管理されている。EC2とは別の料金が発生する。  

リザーブドインスタンス：１～３年など長期的にインスタンスを利用する場合に、契約すると最大で７０％ほど割引される。
スポットインスタンス：AWSが管理している

キャパシティの予約：特定のAZのEC2インスタンスに対して任意の期間キャパシティを予約することで、

ハードウェア専有インスタンス：専用のHWのVPCで実行されるEC2インスタンス
Dedicated Host：EC2インスタンス容量を完全にお客様専用として利用できる物理サーバ。  
Bare Metal：アプリが基盤となるサーバのプロセッサとメモリに直接アクセス可能なインスタンス。  

リザーブドインスタンスの特徴
利用期間を長期指定して利用する形式で、オンデマンドに比較して最大７５％割安になる。
リザーブドインスタンスの種類
スタンダード
コンパーティブル

スポットインスタンスの特徴
一時的にAWSが用意しているコンピューティング容量を用いてインスタンスを動作させるため、最大９０％割引される。  
ただし、予備用のコンピューティング容量のため途中で削除される可能性がある一時利用用のインスタンス  
事前に上限価格とインスタンスタイプを選択し、上限内まで利用可能。  
スポットフリートを利用することで、自動でスポットインスタンスのリクエストを最適化できる。  
EC2フリートの利用  
オンデマンド、リザーブド、スポットインスタンスで構成されるインスタンスセットを定義する仕組み。  

EC2のリカバリー  
定期的なAMI、データをスナップショットでバックアップを取る必要がある。  
CloudWatchによりインスタンスのステータスをモニタリングする。  
キャパシティの予約は、細かいスケジュールで、ホストを専有できる機能  

プレイスメントグループは、EC2インスタンスをグループ化する機能  
ロードバランサーは、複数のEC2インスタンス

EC2が高負荷になった際に、自動でインスタンスを起動する機能で、AutoScalingがある。

ユーザデータ
⇒インスタンス起動時に自動でソフトウェアのインストールなど実行する 

公開鍵で暗号化して、秘密鍵で復号化する  

データベースを設定する構成パターンは３つ
* 単一のインスタンスにWebサーバとDBをインストールする
* EC2インスタンスを複数用意し、一方にWebサーバ、一方にDBを配置する。DBはプライベートサブネットに、Webサーバはパブリックサブネットに配置する。  
* EC2を複数用意し、パブリックサブネットにEC2インスタンスを、プライベートサブネットにRDSのAWSサービスを利用する  

インスタンスを起動する際に、インスタンス内でインストールするパッケージや設定を自動化することをユーザデータという。  

起動テンプレートというインスタンスを生成する際に設定するインスタンスタイプやネットワーク設定などのテンプレートを作成することができる。このテンプレートを使うことで、インスタンス生成を自動でできる。 


外部ステージは、SnowflakeからAWSのS3バケット上の特定のフォルダを参照する。
外部ステージを使うことで、S3バケット上のファイルをCOPYコマンドでSnowflakeのテーブルにロードできる。  

ただし、COPYを実行するには、SnowflakeのAWSアカウントからS3バケットが存在するAWSアカウントへの読み込み権限が必要。 
ストレージ統合を使うことで、S3バケットに対する読み込みを許可するIAMロールの権限を取得できる。  

## RDS
Amazon Relational Database ServiceとはAWSで使用できるリレーショナルデータベース。  

## RDSの特徴
* 高速化
  * RDSでリードレプリカを使用してDBを高速化することができる。リードレプリカとは、読み取り専用のDB。これを複数設置することで  
  * 大量の読み込みリクエストが来てもパフォーマンスを落とさずに処理が可能。  
* 可用性と耐久性
  * マルチAZ配置することで可用性と耐久性が可能。
  * マルチAZ配置では、スタンバイレプリカ（バックアップ用DB）とプライマリDB(元のDB)とは別のAZに配置する。  
  * もし、プライマリDBに何等かの障害が発生した場合はスタンバイレプリカに自動的に切り替え、サービスへの影響を抑える  
* 高いスケーラビリティ
  * DBを停止することなくストレージを追加することが可能  
* 暗号化
  * KMSやAWS CloudHSMという暗号化サービスを使うことができる  
* 複数のDBエンジンを使用することが可能
  * Oracle
  * MySQL
  * MariaDB
  * SQL Server
  * PostgreSQL
  * Amazon Aurora


## ELB
Elastic Load Balancingとは、外部からのリクエストを複数のサーバに振り分け負荷分散するロードバランサーのサービス  
AWSのELBはアプリケーションへの負荷やCPUの稼働状況をリアルタイムにモニタリングできるロードバランサー。  
これにより、システムのボトルネックを見つけて、アクセスを自動的に分散する.  
ヘルスチェック機能もあり、ロードバランサーの内側にあるサービスの状態をモニタリングできる  

ELBのほかにも、Webサービスに発生する負荷を分散するALB(Application Load Balancing)なNLBなどがある。  
ELBは総称であり、４つの種類がある。  

* ALB：HTTP、HTTPSのレイヤー７に対応する単一ロードバランサー。Webアプリで用いられる  
* NLB：TCP、UDPのレイヤー４で動作し、リクエストの内容によってターゲットをに振り分ける。低遅延で大量のアクセスを分散することが可能。  
* CLB：複数のEC2に対して負荷分散を行う。


単一EC2インスタンス+複数のRDSの場合、RDSはマルチAZに配置していた場合、スタンバイレプリカにプライマリDBがダウンしても切り替える冗長化構成が取れているが、EC2は単一だと障害が発生した場合サービスにアクセスできなくなる  

別々のAZ・サブネットに複数のEC2を用意した場合でも、片方に障害が発生した場合、ユーザ側で接続先のEC2を指定しなければならない。  

要するに、ユーザが接続先のEC2を意識せずとも負荷分散・障害発生時に接続先を自動切換え可能な機能が必要  

そこで使うのがELB。  
ELBはユーザから見たアクセス先をDNS名を指定する。  
ユーザからはELBにアクセスし、ELBからEC2にリクエストを振り分ける  
また、ELBでは以下の機能がある  
・ヘルスチェック：異常なインスタンスを検知し、通信をストップしてくれる機能。ヘルスチェックの対象として登録されたEC2へ定期的にリクエストを送信し、正常なレスポンスが返ってくるかで確かめる

・

RDSは停止中もストレージ料金が発生する
停止したRDSインスタンスは１週間で自動起動される

フェイルオーバーとは、プライマリDBが壊れたときに、予備機（スタンバイレプリカ）に自動切換えすること

* 可用性と耐久性

## サーバレスの目的
開発者はユーザに価値を提供することが目的にもかかわらず、サーバなど考えることが多い  
そこで、開発に特化し、余計なインフラの管理を省いたのがサーバレス  

## APIとは
プログラムやソフトウェア同士がやり取りするための取り決め・仕様  

Web APIを開発するときに考えるべきこと
* API自体の開発
* 高可用性・スケーラビリティ設計
* インフラの管理
* APIキーの管理
* デプロイ管理

API Gatewayを用いれば、API自体の開発のみに注力することが可能  

API Gatewayの機能

* リソースとメソッドタイプの定義
  * どのリソース(指定したUser IDに対して)に、どんな操作(GET, POSTなど)をするのか指定する
* メソッドリクエスト設定
  * リクエストの受付に関する設定を行う。認証の設定、受け付けるクエリパラメータなど、
* 統合タイプ設定
  * 統合バックエンドの種別を選択する(Lambda、HTTP、Mock、AWSサービス、VPCなど)
* Req/Res変換定義
  * 統合バックエンドへの入力データ、バックエンドからの出力データを変換できる。
  * プロキシ統合は変換せずにパススルーすることができる機能
* デプロイ
  * API単位にデプロイする。デプロイする際はステージを作成する必要がある

APIキーを作成して、使用量プラン(10000リクエストでXX円)を作成することができる。


DynamoDBの特徴

* 3つのAZに作られるので、信頼性が高い  

テーブルを作成する際に、プライマリーキーを作成する必要がある。
プライマリーキーには、パーティションキーとソートキーを用いる。
いずれか片方でも問題ない。  

つまり、パーティションキーのみをプライマリーキーとした場合、パーティションキーが重複してテーブルに登録することはできない  

LSIはソートキー以外に絞り込み検索を行うキーをもつことができる
パーティションキーはベーステーブルと同じ

キャパシティユニット
Read、Writeそれぞれのデータの読み・書き込み容量。
Read：1ユニットにつき、最大４KBのデータを読み込み可能
Write：1ユニットにつき、最大１KBのデータの書き込みが可能  

Dynamo DBではHTTPベースのAPIで操作を行う

データ作成：PutItem
データ取得：GetItem
複数データ取得：Query(指定したキーのみ), Scan(テーブルまたはセカンダリインデクスすべてを取得する
データの更新：UpdateItem

## なぜ監視が必要なのか
リソース監視
  CPU使用率、ストレージ使用料
ログ監視
  AWSサービス、OS、アプリケーション、ミドルウェア等

## AWSの監視サービス
* CloudWatch
  * メトリクス：CPUやメモリ使用率など
  * Logs：アプリケーションのログなど
* X-Ray
  Traces：アプリケーションの実行状況など
  
  ## AWS CloudFormation
  テンプレートファイルを使用して、システムをまとめて環境構築ができるサービス
  
  CPU使用率・メモリ使用率の確認⇒CloudWatch Metrics
  アプリケーションのログを収集するのにCloudWatch Logsがある
  ログを可視化するのに、CloudWatch Logs Insightsがある  
  
  メトリクスに応じたアクション（アラームなど）を実行するCloudWatch Alarmがある  
  
  リソース監視
  アプリケーション性能監視
  
  ClodWatchに発行されたメトリクス(CPU使用率など)を収集し、統計を取得

データポイントはタイムスタンプと測定データを保持  
メトリクスは時系列のデータポイントのセット  

名前空間
ディメンション：メトリクスを一意に識別する名前/値のペア名  

標準メトリクス：CPU・メモリ使用量
カスタムメトリクス：標準メトリクスで対応していないメトリクス（メモリ使用率、ディスク使用率など）  


CloudWatch Logs

システムのログの監視、保存、アクセスを提供  
エージェント経由でログメッセージをCloudWatch Logsに転送する。  
ログデータの保存期間を1日～無期限で設定可能  
転送されたログの容量によって課金される。  
取得したログデータをS3、Kinesisなどに転送される.  

## CloudWatch Logsのディレクトリ階層  
* ロググループ：複数のログストリームで構成される。ディレクトリみたいなもの。
* ログストリーム：複数のログイベントで構成される。監視しているリソースのタイムスタンプ順でイベントを表す。ファイルみたいなもの。
* ログイベント：監視しているリソースで発生したイベントのタイムスタンプとイベントメッセージで構成される。ファイルの中身みたいなもの  
* CloudWatch Logsを使うには、Agentをインストールする必要がある  

CloudWatch Logs Insihtsはログデータを対話的に検索して分析できる機能  
専用のクエリを実行することで検索する  

複数のMetricsやLogsを一つの画面で確認できるのがCloudWatch Dashboardという。  
異なるリージョンのリソースでも、１つのダッシュボードで表示可能  

ダッシュボードは自分で作成することもできるが、Automatic Dashboardを利用することで、AWSのダッシュボードのベストプラクティスに準拠したダッシュボードを自動生成できる  

CloudWatch Events
AWS上のリソースの変更を示すシステムイベントのストリームを提供  
システムイベントをトリガーとして、ターゲットがイベントを通知  


# OpenAI

ChatGPT：AIチャットボットサービス  
Whisper：音声認識サービス  

## Snowpipe
Snowpipeとは、AWSのS3バケットに置かれたファイルのデータをテーブルに自動ロードする機能  
Snowpipeでは以下のフローでテーブルにデータをロードする  

1. S3バケットのフォルダにファイルが置かれたことを検知する
2. S3バケットのイベント通知機能によりファイルの存在がAWSのSQSに通知される
3. 通知後、SnowflakeのからCOPYコマンドが自動実行される  

## 前提条件
Snowflake上にS3バケットの外部ステージが作成されていること


## スケーリングにまつわる課題
ビジネスの拡大とともにマシンリソースの追加が必要  
⇒自動でリソース追加
正確な需要予測は難しく、余剰リソースを見込んだ調達が必要  
⇒需要に基づいた動的なスケーリング  
突発的な需要拡大に対応できずビジネスの機会損失につながる  
⇒スケーリングによる可用性の維持  

## Amazon EC2 Auto Scalingとは
EC2インスタンスを自動追加、削除を行うことで可用性維持、コスト最適化を機能する  

* スケジュールスケーリング
  * 設定されているスケジュールに基づきスケーリングを行う。予測が可能な需要変化への対策となる。
  * 決まった時間にアクセスが集中する、あるいはアクセス数が少なくなるなどの場合、活用がよい  
  * ex. 月曜日8時はインスタンスを追加するなど
* 動的スケーリング
  * 設定された閾値に基づき動的にスケーリングする
    * CPU使用率が９０％を超えたらスケーリングするなど  
  * 予測ができない需要への対策となるが、スケーリングに時間がかかるため、急激なアクセスにおける利用には注意が必要  

## EC2 Auto Scalingのコンポーネント  
* 起動テンプレート
  * 起動されるインスタンスの起動情報を設定するテンプレート
    * AMI
    * インスタンスタイプ
    * ネットワーク設定など
* Auto Scalingグループ
  * どの起動テンプレートを利用するのか
  * 何台構成を維持するか
  * スケールアウトする最大の台数
  * スケールインする最小の台数
  * 何をトリガーにスケールするか

スケジュールスケーリングの流れ
1. 起動テンプレートの作成
2. Auto Scalingグループの作成
3. スケジュールの設定

Auto Scalingグループでは、使用する起動テンプレート、何台構成とするか、最大何台のスケールアウト、最小何台のスケールインにするか設定する  


## スケーリングポリシー
スケーリングポリシーには３種類がある  
* ターゲット追跡スケーリング
* ステップスケーリング
* シンプルなスケーリング

## ターゲット追跡スケーリング
指定したターゲット値を維持するようにスケールアウト・スケールインを行う  
e. 平均CPU使用率を70~80%で維持するようにスケーリングする  

スケールアウト：インスタンスを追加すること  
スケールイン：インスタンスを削減すること

ターゲット追跡スケーリングの確認
1. ターゲット追跡スケーリングの設定


## スケジュールスケーリングと動的スケーリングの組み合わせ  
例えば、急激なアクセス増加であるがタイミングを予測でき、その後緩やかに減少する場合、急激なアクセス増加のタイミングを  
スケジュールスケーリングでスケールアウトし、アクセス数が減少し、インスタンスをスケールインする際には必要最低限のインスタンス数を  
確保しながら、スケールアウトするために動的スケーリングを活用する。  

## スケーリングを前提としたアプリケーション設計
スケーリングによってインスタンス数が増減するため、特定のサーバに依存するようなステートフルな設計ではなく、ステートレスな設計が必要  
例えば、ログファイルやセッション情報をDynamo DBやElasticCacheに出力・管理するなど。サーバ内で保持しないようにする必要がある  

## 異常なインスタンスの置き換え
AutoScalingにはEC2のステータスチェックまたは、ELBのヘルスチェックに応じて異常なインスタンスを新しいインスタンスに置き換える  
アクセス増減に伴うスケーリングだけでなく、AutoScalingグループ内の異常なインスタンスを置き換えることによって可用性を維持する  

## Web API
HTTPやHTTPSなどの通信で、JSON形式でデータをやり取りする仕組みをWeb APIという  

API Gatewayでは、外部からアクセス可能なURLを用意する  
実際の処理は他のAWSサービスで実施する（Lambdaなど）  


## SAM
サーバレスアプリケーション構築用のオープンソースフレームワーク  
SAMテンプレートもYAML形式もしくはJSON形式で記述できる  
SAM CLIも提供されている  

## SAMテンプレートの書き方
* リソースタイプを選択
  * AWS::Serverless::Function
  * AWS::Serverless::Api
  * AWS::Serverless::SimpleTable
  * など６種類
  * CloudFormationのTypeも利用可能

* リソースタイプごとに必要なプロパティを記述
  * AWS::Serverless:Functionであれば、Handler、Runtime、CodeUri、などなど

## SAMの利用の流れ

1. SAMテンプレートを記述
2. パッケージングする
  * cloudformationのテンプレートにパッケージングする際に、元ファイルをzip化する
4. デプロイする
  * cloudformationの機能でAWSリソースの作成を行う

## CloudFormation
AWSリソースのモデル化、およびセットアップ  
利用するAWSリソースをテンプレートに記述すると、各リソースのプロビジョニング・設定をAWS CloudFormationが実施する  
スタックを削除すれば、リソース群をまとめて削除可能  

## AWS Cloud9
ブラウザのみでコードを記述、実行、デバッグが可能なクラウドベースのIDE  
複数人でリアルタイムで共同コーディングも可能  
EC2インスタンスとEBSの料金分  


## TO_TIMESTAMP
入力式を対応するタイムスタンプに変換する  
TO_TIMESTAMP_LTZ:現地時間帯のタイムスタンプ
timezoneセッションパラメータの値に応じて、タイムゾーンが動的に変化するTIMESTAMP。  
例えば、timezoneパラメータをAmerica/Los_Angelesにした場合、  

```
create or replace table ts_test(ts timestamp_ltz;

alter session set timezone = 'America/Los_Angeles';

insert into ts_test values('2014-01-01 16:00:00');
insert into ts_test values('2014-01-01 16:00:00 +00:00:00' );

```
上記のクエリを実行した場合、463行目のタイムゾーンを指定した場合については、タイムゾーン分の時間が変更されるが、タイムゾーンを指定していないと、何も変更されない  



TO_TIMESTAMP_NTZ：タイムゾーンなしのタイムスタンプ  
レコード登録時のタイムゾーンもtimezoneセッションパラメータも、どちらも影響を受けないTIMESTAMP  
例えば、timezoneパラメータをAmerica/Los_Angelesにした場合、  

```

create or replace table ts_test(ts timestamp_ntz);

alter session set timezone = 'America/Los_Angeles';

insert into ts_test values('2014-01-01 16:00:00');
insert into ts_test values('2014-01-01 16:00:00 +00:00:00' );

```

上記を実行した場合、レコード登録時にタイムゾーンを指定していたとしても、していなかったとしても時刻が変化しないのがTIMEZONE_NTZの特徴  

TO_TIMESTAMP_TZ：タイムゾーン付きのタイムスタンプ  

## データ分析プロジェクト

良い目的とは
* ビジネス観点：ROI(投資対効果)と照らし合わせ、達成すると何らかの利益があり、関係者の納得感を得られる  
* データ分析観点：達成するための方法を想定でき、達成を何らかの方法で達成すること  

ゴールとの距離  
進行の確認：計画書と照らし合わせる
状態の確認：事業に関連する情報（KPIなど）を確認  

## データ分析の文脈での評価スキル
データサイエンスの評価スキルは目的達成評価のために用いられることが多い。  
仮説検証：意思決定のために実験する
モデル評価（機械学習）：作成したモデルの効果を評価  

基本的に利益が上がっているかをモニタリング  
⇒事前に決められた成功を示す指標をチェックする
プロジェクトの目的や計画があいまいな場合、KPIマネジメントという手法が有効  

KGI：最終的に期末に達成したい最も重要な数値目標  
CSF：成功のためにおく仮説  
KPI：事業成功のために選択した手段の成否を定量的にはかれるようにした数値目標  

ようするに、、  
KGI：最終的に達成したい目標（売上、利益などすぐには変えられない目標）  
CSF：KGIを達成するために「～をすれば、kGIを達成できるかも」という仮説
KPI：CSFで立てた仮説を達成できているかの指標。(アプリ利用時間、サービス売上など)  KPIは努力すれば買えられる  

## KPI設定その１：CSFの設定  
KGI向上のための重要な要素を考える
⇒仮説をもとに施策やプロジェクト、組織のせいしつを加味する  
⇒直接操作が

重要な要素を指標とする  

## KPIの設定その２：標間の関係性整理
1. リストアップした要素に対して取得可能性と照らし合わせて指標を作成し、それぞれの関係を整理する
  どの指標とどの指標が、どう連動しているかを考える  
  それぞえの指標の変化が良いこと・悪いこと・どちらともいえないことなどの仮説を立てる  
3. それらの指標について、KGI、KPI、分析用指標の3つに分ける  

## KPIの設定その３：KPIの望ましい性質
* 説明可能性：定義やその意義がわかりやすい。上昇・下降の意味づけができる  
* 操作可能性：施策を行うことによって変動するものであること
* KGIとの関連：事前のぶんせきで関連性のあるもの
* 安定性：指標の変動に一喜一憂しないようなもの  

## よく用いられるKPIの例
DAU：日別のユーザ数
MAU：月別のユーザ数
CVR：ユーザ当たりのコンバージョン数（重要なアクション数）  
⇒ECサイトなら、購入がコンバージョンにあたる  

CTR：とあるページからとあるページへ遷移した数の割合
⇒ユーザに対して興味のあるページが、内容が表示できているかを指標
PV：とあるページのアクセス数  
リテンション：連続で利用しているユーザの割合  
⇒7日のうち、同じユーザが利用しているユーザ数がどれだけなのか  
直帰率：とあるページを見て離脱したユーザの割合  

上記のKPIからリリースしたサービスがKGIに向かっているのか判別できる  

KPIは常に監視しておく必要があるが、それ以外の指標(分析用指標)についても監視する  

* KPIの変動の理解のために補助的に使う
* KPI以外の指標が大きく場合は何かが起こっているシグナル⇒分析を通じて明らかにする必要がある  
* モニタリングを通じて当初の仮説を検証していく  

## 指標のモニタリング方法
モニタリング情報の集約：表データ（Excelなど）で定期的に集約  

共有や議論のための場を作る  

## KPIモニタリング時の注意
* KPIの運用は長期的になる
* 数字規模と変動の感覚をつかむ
* 重要な数字の変化に気づける
* 細かい数字の変化に踊らされない


## バブルチャート
点（バブル）のサイズを使って、追加データを表現する
バブルチャートとは、３つの異なる変数のデータを比較することが可能なグラフ。  
バブルチャートでは、縦軸、横軸に加えて、各店のサイズも追加可能  

つまり、サイズからデータの影響度合いを表現できる  
ようするに、バブルが大きいほど、影響が大きいということ  


## バブルチャートが良く用いられるケース
バブルチャートの活用例として、PPM分析がある  
PPM分析とは、商品や事業の現在の状態と将来性を分析する方法  
⇒縦軸：市場成長率、横軸：市場独占率、バブル：売上高
⇒市場独占率は高くて売上高も高いのに、市場成長率が低いなど、３つの変数のデータを使って比較や分析が可能  

## 箱ひげ図
各データの最大値、最小値、中央値、２５％の位置の値、７５％点の値を確認できる。

## モデル作成の流れ
* パッケージ、ライブラリのインポート
* データを読み込む
* EDA（探索的データ分析）
  * データの可視化や統計指標により、データそのものの傾向・特徴を把握する
* 特徴量エンジニアリング
* アルゴリズムの学習
* 予測
* submit

## 特徴量エンジニアリング
1. データをアルゴリズムが認識できる形に変換
  * 例えば、文字データを数値に変換したり、欠損値を平均などで補完したりなど
2. アルゴリズムの予測に有用な特徴量の作成

## One-Hotエンコーディング
0と1だけでデータの種類を表現する  
⇒データサイズの増加が懸念となる  

## ランダムフォレスト
決定木をベースとした拡張アルゴリズム  
決定木：一つの特徴量に一つの閾値を定め、条件分岐を繰り返して予測値を決定する  
ランダムフォレストは、複数の決定木から出力した予測値から最終的な出力をするアルゴリズム  

アンサンブル学習：複数の学習モデルからの出力を元に予測するアルゴリズム  


## 精度向上に向けて
* 教師データの加工修正
  * 特徴量エンジニアリング（特徴量の追加・削除）
* アルゴリズムの変更、パラメータチューニング

## ロジスティック回帰
線形回帰(y = ax + b)の出力を0～1の確率に変換したもの  
２値分類に特化しているアルゴリズムであるため、２値分類である場合、利用可能  
出力した確率が0.5以上であれば、1を出力、0.5未満であれば0を返す


## 機械学習アルゴリズムチートシート
2値分類問題の場合、ロジスティック回帰で精度向上を目指す
多値分類問題の場合、決定木やランダムフォレストなどが良い  

データに偏りがある場合には、データを分割することで精度が向上することがある  
似たデータを持つ場合、組み合わせることで精度が向上することがある  


## LightGBM
勾配部ースティング法で、大量に決定木を作成しながら学習を行う  
以前の決定木の誤差を学習して、誤差を最小化するように次の決定木を作成するため、精度が高いモデルを作成できる  
データ量が大量にあれば制度が良いが、処理時間が長い、過学習が発生する可能性がある  

外れ値を除去しないまま、学習すると学習モデルに外れ値も含まれてしまい、教師データにフィットする過学習が発生する  
⇒外れ値は除去する必要がある  

## 学習用データと検証用データ
学習用データセットから検証用データセットを作成し、モデルの性能を事前に検証する  
⇒過学習を起こさせないため  

つまり、、    
学習データ  
検証データ  
テストデータ  
の三つがある  

